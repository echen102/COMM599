{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Retweet Network\n",
    "\n",
    "In this tutorial, we will be creating a Twitter retweet network from a set of tweets. \n",
    "\n",
    "Note that public Twitter data sets that you will find will only contain the Tweet IDs (as per Twitter's policy), so you will have to \"rehydrate\" each tweet by using the Twitter API to request the full text. \n",
    "\n",
    "We'll also be using Tweepy - which is a python wrapper that allows us to use the Twitter API. Of course, the Twitter API can be accessed directly as well, but Tweepy has a few extras that makes getting Tweets just a bit easier. \n",
    "\n",
    "We provide two ways of visualizing the graph itself - one through iGraph and the other by exporting the networkx generated network into a Gephi file (note that the extension is deprecated by Gephi but is what networkx supports and still works).  \n",
    "\n",
    "### Resources and Links\n",
    "https://gephi.org/\n",
    "\n",
    "http://docs.tweepy.org/en/latest/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import wget\n",
    "import igraph as ig\n",
    "import tweepy\n",
    "\n",
    "# Save the location of the Tweet JSON file\n",
    "TWEET_JSON = \"covid.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our tweet dictionary that filters out all the information we are not interested in\n",
    "# a clean tweet object extracts and contains the following attributes from the raw tweet: \n",
    "# the original tweet's : id, user, text\n",
    "# if the tweet is a retweet, our object also contains the retweet's: rt_text, rt_user, rt_id\n",
    "# along with a boolean value is_rt that indicates whether the current tweet is a retweet. \n",
    "\n",
    "def clean_tweet(tweet): \n",
    "    processed_tweet = {\n",
    "        \"id\" : tweet['id'], \n",
    "        \"user\" : tweet['user']['screen_name'], \n",
    "        \"created_at\" : tweet['created_at'], \n",
    "        \"text\" : \"\"\n",
    "    }\n",
    "    if \"extended_tweet\" in tweet: \n",
    "        processed_tweet[\"text\"] = tweet['extended_tweet']['full_text']\n",
    "    elif \"full_text\" in tweet: \n",
    "        processed_tweet[\"text\"] = tweet['full_text']\n",
    "    elif \"text\" in tweet: \n",
    "        processed_tweet[\"text\"] = tweet['text']\n",
    "        \n",
    "    if 'retweeted_status' in tweet:\n",
    "        rt = tweet['retweeted_status']\n",
    "        processed_tweet[\"is_rt\"] = True\n",
    "        processed_tweet[\"rt_user\"] = rt['user']['screen_name']\n",
    "        processed_tweet[\"rt_id\"] = rt['id'] \n",
    "        processed_tweet[\"rt_text\"] = \"\"\n",
    "        if 'extended_tweet' in rt: \n",
    "            processed_tweet[\"rt_text\"] = rt['extended_tweet']['full_text']\n",
    "        elif \"full_text\" in rt:\n",
    "            processed_tweet[\"rt_text\"] = rt['full_text']\n",
    "        elif \"text\" in rt: \n",
    "            processed_tweet[\"rt_text\"] = rt['text']\n",
    "    else: \n",
    "        processed_tweet[\"is_rt\"] = False\n",
    "            \n",
    "    return processed_tweet\n",
    "            \n",
    "# load the raw tweets into a list\n",
    "tweet_data = []\n",
    "with open(TWEET_JSON) as f:\n",
    "    for line in f:\n",
    "        json_line = json.loads(line)\n",
    "        tweet_data.append(json_line)\n",
    "\n",
    "# filter all of the raw tweets by turning them into clean_tweet objects\n",
    "# the filtering is taken care of in the class function\n",
    "filtered_data = []\n",
    "for elem in tweet_data: \n",
    "    filtered_tweet = clean_tweet(elem)\n",
    "    filtered_data.append(filtered_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# priting out the filtered_data, which contains clean_tweet objects \n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first element of the unfiltered data as an example\n",
    "print(tweet_data[0])\n",
    "print (\"---\")\n",
    "# printing an example of a retweet object as an example\n",
    "print(tweet_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the first element of the filtered data\n",
    "print(filtered_data[0])\n",
    "print (\"---\")\n",
    "# printing an example of a retweet object\n",
    "print(filtered_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many total tweets we have\n",
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting New Tweets\n",
    "\n",
    "We now walk through how to use the search and stream Twitter APIs. Before you can, you'll need to create a developer account and create/register your application wtih Twitter to get the necessary authentication keys. \n",
    "\n",
    "https://developer.twitter.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\"api_key\": \"\",\n",
    "        \"api_secret\": \"\",\n",
    "        \"access_token\": \"\",\n",
    "        \"access_secret\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the Twitter Search API to look up past tweets\n",
    "# We save our tweets to a file called \"covid_search.json\"\n",
    "auth = tweepy.OAuthHandler(info['api_key'], info['api_secret'])\n",
    "auth.set_access_token(info['access_token'], info['access_secret'])\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "count = 0\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q=\"covid\",\n",
    "                           include_entities=True,\n",
    "                           tweet_mode='extended',\n",
    "                           lang=\"en\").items():\n",
    "    \n",
    "    tweet_json = json.dumps(tweet._json)\n",
    "    with open (\"covid_search.json\", \"a+\") as search_f:\n",
    "        json_text = json.dumps(tweet._json)\n",
    "        search_f.write(json_text)\n",
    "        search_f.write('\\n')\n",
    "    if count > 100: \n",
    "        break\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the Twitter Stream API to get tweets in real time\n",
    "# We save our tweets to a file called \"covid_stream.json\"\n",
    "#override tweepy.StreamListener to add logic to on_status and on_error \n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, status):\n",
    "        print(status._json)\n",
    "        with open (\"covid_stream.json\", \"a+\") as stream_f:\n",
    "            json_text = json.dumps(status._json)\n",
    "            stream_f.write(json_text)\n",
    "            stream_f.write('\\n')\n",
    "            \n",
    "    def on_error(self, status_code):\n",
    "        print(\"Error detected!\")\n",
    "        print (status_code)\n",
    "        return False\n",
    "    \n",
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)\n",
    "myStream.filter(track=['covid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw tweets found from the search and stream apis into the same list for processing\n",
    "new_tweet_data = []\n",
    "with open(\"covid_search.json\") as new_search_f:\n",
    "    for line in new_search_f:\n",
    "        json_line = json.loads(line)\n",
    "        new_tweet_data.append(json_line)\n",
    "        \n",
    "with open(\"covid_stream.json\") as new_stream_f:\n",
    "    for line in new_stream_f:\n",
    "        json_line = json.loads(line)\n",
    "        new_tweet_data.append(json_line)\n",
    "# filter all of the raw tweets by turning them into clean_tweet objects\n",
    "# the filtering is taken care of in the class function\n",
    "\n",
    "new_filtered_data = []\n",
    "for elem in new_tweet_data: \n",
    "    new_filtered_tweet = clean_tweet(elem)\n",
    "    new_filtered_data.append(new_filtered_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of one of our new tweets\n",
    "new_filtered_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the two lists together to form a full list to send into our graph\n",
    "total_filtered_data = filtered_data + new_filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a directed graph for retweet graph\n",
    "G=nx.DiGraph()\n",
    "\n",
    "for elem in total_filtered_data: \n",
    "    # for each tweet, we add the tweet's user to the graph\n",
    "    G.add_node(elem[\"user\"])\n",
    "    print (elem[\"user\"])\n",
    "\n",
    "    # if this tweet is a retweet, we add the original tweet's user to the graph\n",
    "    # and create an edge between the current user and the original tweet's user\n",
    "    # current user -> original tweet's user\n",
    "    if elem[\"is_rt\"]: \n",
    "        G.add_node(elem[\"rt_user\"])\n",
    "        print (elem[\"rt_user\"])\n",
    "        G.add_edge(elem[\"user\"], elem[\"rt_user\"])\n",
    "    print (\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out the number of nodes (users) in our graph\n",
    "print (len(G.nodes()))\n",
    "# printing out the number of edges/links in our graph\n",
    "print (len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing our graph to a Gephi file format\n",
    "nx.write_gexf(G, \"covid-total.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing our retweet network\n",
    "# This code was borrowed from the Plotly documentation\n",
    "# https://plot.ly/python/v3/igraph-networkx-comparison/\n",
    "\n",
    "G2 = ig.Graph.TupleList(G.edges(), directed=True)\n",
    "labels=list(G2.vs['name'])\n",
    "N = len(labels)\n",
    "E = [e.tuple for e in G2.es]\n",
    "layt=G2.layout('kk') #kamada-kawai layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is code to visualize the graph. Treat as blackbox for now!\n",
    "import chart_studio.plotly  as py\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "Xn=[layt[k][0] for k in range(N)]\n",
    "Yn=[layt[k][1] for k in range(N)]\n",
    "Xe=[]\n",
    "Ye=[]\n",
    "for e in E:\n",
    "    Xe+=[layt[e[0]][0],layt[e[1]][0], None]\n",
    "    Ye+=[layt[e[0]][1],layt[e[1]][1], None]\n",
    "    \n",
    "trace1=Scatter(x=Xe,\n",
    "               y=Ye,\n",
    "               mode='lines',\n",
    "               line= dict(color='rgb(210,210,210)', width=1),\n",
    "               hoverinfo='none'\n",
    "               )\n",
    "trace2=Scatter(x=Xn,\n",
    "               y=Yn,\n",
    "               mode='markers',\n",
    "               name='ntw',\n",
    "               marker=dict(symbol='circle-dot',\n",
    "                                        size=5,\n",
    "                                        color='#6959CD',\n",
    "                                        line=dict(color='rgb(50,50,50)', width=0.5)\n",
    "                                        ),\n",
    "               text=labels,\n",
    "               hoverinfo='text'\n",
    "               )\n",
    "\n",
    "axis=dict(showline=False, # hide axis line, grid, ticklabels and  title\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=''\n",
    "          )\n",
    "\n",
    "axis=dict(showline=False, # hide axis line, grid, ticklabels and  title\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=''\n",
    "          )\n",
    "\n",
    "width=800\n",
    "height=800\n",
    "layout=Layout(title= \"Twitter Retweet Network\",\n",
    "    font= dict(size=12),\n",
    "    showlegend=False,\n",
    "    autosize=False,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    xaxis=layout.XAxis(axis),\n",
    "    yaxis=layout.YAxis(axis),\n",
    "    margin=layout.Margin(\n",
    "        l=40,\n",
    "        r=40,\n",
    "        b=85,\n",
    "        t=100,\n",
    "    ),\n",
    "    hovermode='closest',\n",
    "    annotations=[\n",
    "           dict(\n",
    "           showarrow=False,\n",
    "            text='',\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            x=0,\n",
    "            y=-0.1,\n",
    "            xanchor='left',\n",
    "            yanchor='bottom',\n",
    "            font=dict(\n",
    "            size=14\n",
    "            )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "data=[trace1, trace2]\n",
    "fig=Figure(data=data, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
